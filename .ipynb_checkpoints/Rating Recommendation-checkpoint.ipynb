{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16605a33",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-29 21:40:28.211620: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import gzip\n",
    "from collections import defaultdict\n",
    "import math\n",
    "import scipy.optimize\n",
    "from sklearn import svm\n",
    "import numpy as np\n",
    "import string\n",
    "import random\n",
    "from sklearn import linear_model\n",
    "import tensorflow as tf\n",
    "\n",
    "# from fastFM import als\n",
    "from scipy.spatial import distance\n",
    "\n",
    "# import pickle\n",
    "import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "# import nltk\n",
    "# from nltk.stem.porter import *\n",
    "# import spacy\n",
    "# from wordcloud import WordCloud\n",
    "# import matplotlib.pyplot as plt\n",
    "# from nltk.corpus import stopwords\n",
    "# from sklearn.metrics import confusion_matrix, precision_score,recall_score, accuracy_score\n",
    "# from sklearn.metrics import ConfusionMatrixDisplay\n",
    "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "# from textblob import TextBlob, Word\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b30a152",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assertFloat(x):\n",
    "    assert type(float(x)) == float\n",
    "\n",
    "def assertFloatList(items, N):\n",
    "    assert len(items) == N\n",
    "    assert [type(float(x)) for x in items] == [float]*N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09c62b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readGz(path):\n",
    "    for l in gzip.open(path, 'rt'):\n",
    "        yield eval(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9840f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readCSV(path):\n",
    "    f = gzip.open(path, 'rt')\n",
    "    f.readline()\n",
    "    for l in f:\n",
    "        u,b,r = l.strip().split(',')\n",
    "        r = int(r)\n",
    "        yield u,b,r\n",
    "def readcsv(path):\n",
    "    f = open(path,'r')\n",
    "    f.readline()\n",
    "    for l in f:\n",
    "        u,i,d,r,t,n = l.strip().split(',')\n",
    "        yield u,i,d,r,t,n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7047d287",
   "metadata": {},
   "source": [
    "## Load Interactions Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d1e3356a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"interactions_train.csv\")\n",
    "data_raw_interactions = pd.read_csv(\"RAW_interactions.csv\")\n",
    "data_raw_interactions = data_raw_interactions[data_raw_interactions['rating']!=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6e830a97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_id            2046\n",
       "recipe_id          4684\n",
       "date         2000-02-25\n",
       "rating              5.0\n",
       "u                 22095\n",
       "i                 44367\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.iloc[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "80b16a70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_id                                                   8937\n",
       "recipe_id                                                44394\n",
       "date                                                2002-12-01\n",
       "rating                                                       4\n",
       "review       This worked very well and is EASY.  I used not...\n",
       "Name: 2, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_raw_interactions.iloc[2,:]#['review']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "61040dbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          Great with a salad. Cooked on top of stove for...\n",
       "1          So simple, so delicious! Great for chilly fall...\n",
       "2          This worked very well and is EASY.  I used not...\n",
       "3          I made the Mexican topping and took it to bunk...\n",
       "4          Made the cheddar bacon topping, adding a sprin...\n",
       "                                 ...                        \n",
       "1132360    Delicious quick thick chocolate sauce with ing...\n",
       "1132363    These were so delicious!  My husband and I tru...\n",
       "1132364    WOW!  Sometimes I don't take the time to rate ...\n",
       "1132365    Very good!  I used regular port as well.  The ...\n",
       "1132366    I am so glad I googled and found this here. Th...\n",
       "Name: review, Length: 1071520, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_raw_interactions.iloc[:]['review']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd3bdcf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratingsTrain = []\n",
    "for l in readcsv(\"interactions_train.csv\"):\n",
    "    ratingsTrain.append(l)\n",
    "\n",
    "ratingsValid = []\n",
    "for l in readcsv(\"interactions_validation.csv\"):\n",
    "    ratingsValid.append(l)\n",
    "    \n",
    "ratingsTest = []\n",
    "for l in readcsv(\"interactions_test.csv\"):\n",
    "    ratingsTest.append(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4cbfad1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratingsPerUser_train = defaultdict(list)\n",
    "ratingsPerItem_train = defaultdict(list)\n",
    "for u,b,_,r,_,_ in ratingsTrain:\n",
    "    ratingsPerUser_train[u].append((b,float(r)))\n",
    "    ratingsPerItem_train[b].append((u,float(r)))\n",
    "\n",
    "users_train = list(ratingsPerUser_train.keys())\n",
    "items_train = list(ratingsPerItem_train.keys())\n",
    "nUsers_train = len(ratingsPerUser_train)\n",
    "nItems_train = len(ratingsPerItem_train)\n",
    "\n",
    "\n",
    "ratingsPerUser_valid = defaultdict(list)\n",
    "ratingsPerItem_valid = defaultdict(list)\n",
    "for u,b,_,r,_,_ in ratingsValid:\n",
    "    ratingsPerUser_valid[u].append((b,float(r)))\n",
    "    ratingsPerItem_valid[b].append((u,float(r)))\n",
    "\n",
    "users_valid = list(ratingsPerUser_valid.keys())\n",
    "items_valid = list(ratingsPerItem_valid.keys())\n",
    "nUsers_valid = len(ratingsPerUser_valid)\n",
    "nItems_valid = len(ratingsPerItem_valid)\n",
    "\n",
    "ratingsPerUser_test = defaultdict(list)\n",
    "ratingsPerItem_test = defaultdict(list)\n",
    "for u,b,_,r,_,_ in ratingsTest:\n",
    "    ratingsPerUser_test[u].append((b,float(r)))\n",
    "    ratingsPerItem_test[b].append((u,float(r)))\n",
    "\n",
    "users_test = list(ratingsPerUser_test.keys())\n",
    "items_test = list(ratingsPerItem_test.keys())\n",
    "nUsers_test = len(ratingsPerUser_test)\n",
    "nItems_test = len(ratingsPerItem_test)\n",
    "ratingsPerUser = ratingsPerUser_train\n",
    "ratingsPerItem = ratingsPerItem_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "532faa80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25076, 160901, 7023, 6621, 12455, 11695)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nUsers_train, nItems_train, nUsers_valid, nItems_valid ,nUsers_test, nItems_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c39ffcb",
   "metadata": {},
   "source": [
    "## Rating Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1321b126",
   "metadata": {},
   "outputs": [],
   "source": [
    "recipe_allRatings = []\n",
    "userRatings = defaultdict(list)\n",
    "\n",
    "for user,item,_,r,_,_ in ratingsTrain:\n",
    "    recipe_allRatings.append(int(float(r)))\n",
    "    userRatings[user].append(int(float(r)))\n",
    "\n",
    "globalAverage = sum(recipe_allRatings) / len(recipe_allRatings)\n",
    "userAverage = {}\n",
    "for u in userRatings:\n",
    "    userAverage[u] = sum(userRatings[u]) / len(userRatings[u])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d318fae",
   "metadata": {},
   "source": [
    "## Bias Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c9210920",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSE(predictions, labels):\n",
    "    differences = [(x-y)**2 for x,y in zip(predictions,labels)]\n",
    "    return sum(differences) / len(differences)\n",
    "\n",
    "alpha = globalAverage\n",
    "betaU = defaultdict(float)\n",
    "betaI = defaultdict(float)\n",
    "\n",
    "class lf_model():\n",
    "    def __init__(self):\n",
    "        self.alpha = globalAverage\n",
    "        self.userBiases = defaultdict(float)\n",
    "        self.itemBiases = defaultdict(float)\n",
    "\n",
    "    def fit(self,lam):\n",
    "        itrs = 100\n",
    "        for i in range(itrs):\n",
    "            if i %10 == 0:\n",
    "                print(i)\n",
    "        for d in ratingsTrain:\n",
    "            u,i,r = d[0],d[1],d[3]\n",
    "            self.alpha += (float(r) - (self.userBiases[u] + self.itemBiases[i]))\n",
    "            self.alpha /= len(ratingsTrain)\n",
    "        for u in ratingsPerUser:\n",
    "            items = [b for b, r in ratingsPerUser[u]]\n",
    "            ratings = [float(r) for b, r in ratingsPerUser[u]]\n",
    "            self.userBiases[u] = sum([ratings[j] - (self.alpha + self.itemBiases[items[j]]) for j in range(len(items))])/(lam + len(set(items)))\n",
    "\n",
    "        for i in ratingsPerItem:\n",
    "            users = [u for u, r in ratingsPerItem[i]]\n",
    "            ratings = [float(r) for u, r in ratingsPerItem[i]]\n",
    "            self.itemBiases[i] = sum([ratings[j] - (self.alpha + self.userBiases[users[j]]) for j in range(len(users))])/(lam + len(set(users)))\n",
    "        return self.alpha, self.userBiases, self.itemBiases\n",
    "\n",
    "    def prediction(self,user, item):\n",
    "        return self.alpha + self.userBiases[user] + self.itemBiases[item]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c36b3d8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n"
     ]
    }
   ],
   "source": [
    "reg = 0.1\n",
    "mod = lf_model()\n",
    "bestalpha, bestuserBiases, bestitemBiases = mod.fit(lam = reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "57608d22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.6400709365660322"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = [np.clip(mod.prediction(u,i),0,5) for u,i,_,_,_,_ in ratingsValid]\n",
    "#preds = [np.clip((alpha+betaU[u] + betaI[i]),0,5) for u,i,_ in ratingsValid]\n",
    "labels = [float(r) for _,_,_,r,_,_ in ratingsValid]\n",
    "validMSE = MSE(preds, labels)#\n",
    "validMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "83ed2787",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.7961348620319624"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test Accuracy \n",
    "preds = [np.clip(mod.prediction(u,i),0,5) for u,i,_,_,_,_ in ratingsTest]\n",
    "#preds = [np.clip((alpha+betaU[u] + betaI[i]),0,5) for u,i,_ in ratingsValid]\n",
    "labels = [float(r) for _,_,_,r,_,_ in ratingsTest]\n",
    "TestMSE = MSE(preds, labels)#\n",
    "TestMSE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c040391",
   "metadata": {},
   "source": [
    "## Latent Factor Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5dba9177",
   "metadata": {},
   "outputs": [],
   "source": [
    "userIDs = {}\n",
    "itemIDs = {}\n",
    "train_interactions = []\n",
    "for u,i,_,r,_,_ in ratingsTrain:\n",
    "    if not u in userIDs: userIDs[u] = len(userIDs)\n",
    "    if not i in itemIDs: itemIDs[i] = len(itemIDs)\n",
    "    train_interactions.append((u,i,float(r)))\n",
    "    \n",
    "valid_interactions = []\n",
    "for u,i,_,r,_,_ in ratingsValid:\n",
    "    if not u in userIDs: userIDs[u] = len(userIDs)\n",
    "    if not i in itemIDs: itemIDs[i] = len(itemIDs)\n",
    "    valid_interactions.append((u,i,float(r)))\n",
    "\n",
    "test_interactions = []\n",
    "for u,i,_,r,_,_ in ratingsTest:\n",
    "    if not u in userIDs: userIDs[u] = len(userIDs)\n",
    "    if not i in itemIDs: itemIDs[i] = len(itemIDs)\n",
    "    test_interactions.append((u,i,float(r)))\n",
    "interactions = train_interactions + valid_interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "96244c87",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-29 18:52:08.115327: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(0.01)\n",
    "class LatentFactorModel(tf.keras.Model):\n",
    "    def __init__(self, mu, K, lamb):\n",
    "        super(LatentFactorModel, self).__init__()\n",
    "        # Initialize to average\n",
    "        self.alpha = tf.Variable(mu)\n",
    "        # Initialize to small random values\n",
    "        self.betaU = tf.Variable(tf.random.normal([len(userIDs)],stddev=0.001))\n",
    "        self.betaI = tf.Variable(tf.random.normal([len(itemIDs)],stddev=0.001))\n",
    "        self.gammaU = tf.Variable(tf.random.normal([len(userIDs),K],stddev=0.001))\n",
    "        self.gammaI = tf.Variable(tf.random.normal([len(itemIDs),K],stddev=0.001))\n",
    "        self.lamb = lamb\n",
    "\n",
    "    # Prediction for a single instance (useful for evaluation)\n",
    "    def predict(self, u, i):\n",
    "        p = self.alpha + self.betaU[u] + self.betaI[i] +\\\n",
    "            tf.tensordot(self.gammaU[u], self.gammaI[i], 1)\n",
    "        return p\n",
    "\n",
    "    # Regularizer\n",
    "    def reg(self):\n",
    "        return self.lamb * (tf.reduce_sum(self.betaU**2) +\\\n",
    "                            tf.reduce_sum(self.betaI**2) +\\\n",
    "                            tf.reduce_sum(self.gammaU**2) +\\\n",
    "                            tf.reduce_sum(self.gammaI**2))\n",
    "    \n",
    "    # Prediction for a sample of instances\n",
    "    def predictSample(self, sampleU, sampleI):\n",
    "        u = tf.convert_to_tensor(sampleU, dtype=tf.int32)\n",
    "        i = tf.convert_to_tensor(sampleI, dtype=tf.int32)\n",
    "        beta_u = tf.nn.embedding_lookup(self.betaU, u)\n",
    "        beta_i = tf.nn.embedding_lookup(self.betaI, i)\n",
    "        gamma_u = tf.nn.embedding_lookup(self.gammaU, u)\n",
    "        gamma_i = tf.nn.embedding_lookup(self.gammaI, i)\n",
    "        pred = self.alpha + beta_u + beta_i +\\\n",
    "               tf.reduce_sum(tf.multiply(gamma_u, gamma_i), 1)\n",
    "        return pred\n",
    "    \n",
    "    # Loss\n",
    "    def call(self, sampleU, sampleI, sampleR):\n",
    "        pred = self.predictSample(sampleU, sampleI)\n",
    "        r = tf.convert_to_tensor(sampleR, dtype=tf.float32)\n",
    "        return tf.nn.l2_loss(pred - r) / len(sampleR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b25222c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelLFM = LatentFactorModel(globalAverage, 2,0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c547cac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainingStep(model, interactions):\n",
    "    Nsamples = 30000\n",
    "    with tf.GradientTape() as tape:\n",
    "        sampleU, sampleI, sampleR = [], [], []\n",
    "        for _ in range(Nsamples):\n",
    "            u,i,r = random.choice(interactions)\n",
    "            sampleU.append(userIDs[u])\n",
    "            sampleI.append(itemIDs[i])\n",
    "            sampleR.append(r)\n",
    "\n",
    "        loss = model(sampleU,sampleI,sampleR)\n",
    "        loss += model.reg()\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients((grad, var) for\n",
    "                              (grad, var) in zip(gradients, model.trainable_variables)\n",
    "                              if grad is not None)\n",
    "    return loss.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3e89f330",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 10, objective = 0.39096725\n",
      "iteration 20, objective = 0.39554006\n",
      "iteration 30, objective = 0.39756948\n",
      "iteration 40, objective = 0.38769653\n",
      "iteration 50, objective = 0.40005404\n",
      "iteration 60, objective = 0.3879717\n",
      "iteration 70, objective = 0.39288425\n",
      "iteration 80, objective = 0.38016325\n",
      "iteration 90, objective = 0.37860376\n",
      "iteration 100, objective = 0.38753504\n"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    obj = trainingStep(modelLFM, train_interactions)\n",
    "    if (i % 10 == 9): print(\"iteration \" + str(i+1) + \", objective = \" + str(obj))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ab5fea42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.6239735216416713"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = [np.clip((modelLFM.predict(userIDs[u], itemIDs[b]).numpy()),0,5) for u,b,_,_,_,_ in ratingsValid]\n",
    "# prediction = [int(p + 0.5) for p in preds]\n",
    "prediction = preds\n",
    "labels = [float(r) for _,_,_,r,_,_ in ratingsValid]\n",
    "validMSE = MSE(preds, labels)\n",
    "validMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3505390a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.7373134500720229"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = [np.clip((modelLFM.predict(userIDs[u], itemIDs[b]).numpy()),0,5) for u,b,_,_,_,_ in ratingsTest]\n",
    "# prediction = [int(p + 0.5) for p in preds]\n",
    "prediction = preds\n",
    "labels = [float(r) for _,_,_,r,_,_ in ratingsTest]\n",
    "TestMSE = MSE(preds, labels)\n",
    "TestMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b137a7ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7adb6e3c",
   "metadata": {},
   "source": [
    "## Factorization Machine (fastFM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b79b2e6",
   "metadata": {},
   "source": [
    "Build the factorization machine design matrix. Note that each instance is a row, and the columns encode both users and items. Other features could straightforwardly be added."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd01c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = scipy.sparse.lil_matrix((len(ratingsTrain), nUsers_train + nItems_train))\n",
    "X_valid = scipy.sparse.lil_matrix((len(ratingsValid), nUsers_valid + nItems_valid))\n",
    "X_test = scipy.sparse.lil_matrix((len(ratingsTest), nUsers_test + nItems_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf0c4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "userIDs,itemIDs = {},{}\n",
    "\n",
    "for d in ratingsTrain:\n",
    "    u,i = d[0],d[1]\n",
    "    if not u in userIDs: userIDs[u] = len(userIDs)\n",
    "    if not i in itemIDs: itemIDs[i] = len(itemIDs)\n",
    "\n",
    "nUsers,nItems = len(userIDs),len(itemIDs)\n",
    "\n",
    "for i in range(len(ratingsTrain)):\n",
    "    user = userIDs[ratingsTrain[i][0]]\n",
    "    item = itemIDs[ratingsTrain[i][1]]\n",
    "    X_train[i,user] = 1 # One-hot encoding of user\n",
    "    X_train[i,nUsers + item] = 1 # One-hot encoding of item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab413715",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target (rating) to predict for each row\n",
    "y_train = np.array([d[3] for d in ratingsTrain])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54f0f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the factorization machine\n",
    "fm = als.FMRegression(n_iter=1000, init_stdev=0.1, rank=5, l2_reg_w=0.1, l2_reg_V=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a41622e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model \n",
    "fm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be4400e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract Prediction of the validation set\n",
    "y_pred = fm.predict(X_alid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f468fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c3b32b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d0b88c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7143f60b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79406481",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06798c05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eed8f5ff",
   "metadata": {},
   "source": [
    "## Surprise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "337c7e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import SVD, Reader, Dataset\n",
    "from surprise.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "406ca988",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>recipe_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2046</td>\n",
       "      <td>4684</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2046</td>\n",
       "      <td>517</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1773</td>\n",
       "      <td>7435</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1773</td>\n",
       "      <td>278</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2046</td>\n",
       "      <td>3431</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  recipe_id  rating\n",
       "0     2046       4684     5.0\n",
       "1     2046        517     5.0\n",
       "2     1773       7435     5.0\n",
       "3     1773        278     4.0\n",
       "4     2046       3431     5.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"interactions_train.csv\")\n",
    "data = data[['user_id', 'recipe_id', 'rating']]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f410cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = Reader(rating_scale=(1, 5))\n",
    "# reader = Reader(line_format='user item rating', sep=',', skip_lines = 1)\n",
    "data = Dataset.load_from_df(data, reader=reader)    \n",
    "trainset = data.build_full_trainset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac5d125c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>recipe_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8937</td>\n",
       "      <td>44551</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>56680</td>\n",
       "      <td>126118</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>349752</td>\n",
       "      <td>219596</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>628951</td>\n",
       "      <td>82783</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>92816</td>\n",
       "      <td>435013</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  recipe_id  rating\n",
       "0     8937      44551     4.0\n",
       "1    56680     126118     4.0\n",
       "2   349752     219596     0.0\n",
       "3   628951      82783     2.0\n",
       "4    92816     435013     3.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"interactions_test.csv\")\n",
    "data = data[['user_id', 'recipe_id', 'rating']]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c5525a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "# Reader(line_format='user item rating', sep=',', skip_lines = 1)\n",
    "testset = Dataset.load_from_df(data, reader=reader)    \n",
    "# testset = testset.build_full_trainset()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a7c9fe32",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "predict() missing 1 required positional argument: 'iid'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/05/xmcglcvx5mn55bpwbs2f7kdw0000gn/T/ipykernel_18051/1260560749.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# algo.test(testset)[:2]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;31m# sse = 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# for p in predictions:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: predict() missing 1 required positional argument: 'iid'"
     ]
    }
   ],
   "source": [
    "# Standard latent-factor model\n",
    "model = SVD()\n",
    "# model = SVD(n_epochs = 50, lr_all = 0.0047, reg_all = 0.32)\n",
    "\n",
    "model.fit(trainset)\n",
    "predictions = model.predict(testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acfb7bf2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d80ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "l = [1, 2, 3]\n",
    "m = [4, 5, 6]\n",
    "n = [7, 8, 9]\n",
    "l+m+n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4392640",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
