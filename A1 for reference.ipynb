{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "301bf995",
      "metadata": {
        "id": "301bf995"
      },
      "outputs": [],
      "source": [
        "import gzip\n",
        "from collections import defaultdict\n",
        "import math\n",
        "import scipy.optimize\n",
        "from sklearn import svm\n",
        "import numpy as np\n",
        "import string\n",
        "import random\n",
        "import string\n",
        "from sklearn import linear_model\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "31cab31f",
      "metadata": {
        "id": "31cab31f"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "33f967ad",
      "metadata": {
        "id": "33f967ad"
      },
      "outputs": [],
      "source": [
        "def assertFloat(x):\n",
        "    assert type(float(x)) == float\n",
        "\n",
        "def assertFloatList(items, N):\n",
        "    assert len(items) == N\n",
        "    assert [type(float(x)) for x in items] == [float]*N"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3e25a33f",
      "metadata": {
        "id": "3e25a33f"
      },
      "outputs": [],
      "source": [
        "def readGz(path):\n",
        "    for l in gzip.open(path, 'rt'):\n",
        "        yield eval(l)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f88efc3b",
      "metadata": {
        "id": "f88efc3b"
      },
      "outputs": [],
      "source": [
        "def readCSV(path):\n",
        "    f = gzip.open(path, 'rt')\n",
        "    f.readline()\n",
        "    for l in f:\n",
        "        u,b,r = l.strip().split(',')\n",
        "        r = int(r)\n",
        "        yield u,b,r\n",
        "def readcsv(path):\n",
        "    f = open(path,'r')\n",
        "    f.readline()\n",
        "    for l in f:\n",
        "        u,b = l.strip().split(',')\n",
        "        yield u,b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "09ac1dc4",
      "metadata": {
        "id": "09ac1dc4"
      },
      "outputs": [],
      "source": [
        "allRatings = []\n",
        "for l in readCSV(\"train_Interactions.csv.gz\"):\n",
        "    allRatings.append(l)\n",
        "\n",
        "pairs_Ratings =[l+ (0,) for l in readcsv(\"pairs_Rating.csv\")]\n",
        "pairs_Read = [l for l in readcsv(\"pairs_Read.csv\")]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ca3c2a44",
      "metadata": {
        "id": "ca3c2a44"
      },
      "outputs": [],
      "source": [
        "ratingsTrain = allRatings[:190000]\n",
        "ratingsValid = allRatings[190000:]\n",
        "ratingsPerUser = defaultdict(list)\n",
        "ratingsPerItem = defaultdict(list)\n",
        "for u,b,r in allRatings:\n",
        "  ratingsPerUser[u].append((b,r))\n",
        "  ratingsPerItem[b].append((u,r))\n",
        "\n",
        "users = list(ratingsPerUser.keys())\n",
        "items = list(ratingsPerItem.keys())\n",
        "nUsers = len(ratingsPerUser)\n",
        "nItems = len(ratingsPerItem)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Rating Prediction\n"
      ],
      "metadata": {
        "id": "EhKYIYG4300Y"
      },
      "id": "EhKYIYG4300Y"
    },
    {
      "cell_type": "code",
      "source": [
        "b_allRatings = []\n",
        "userRatings = defaultdict(list)\n",
        "\n",
        "for user,book,r in allRatings:\n",
        "  r = int(r)\n",
        "  b_allRatings.append(r)\n",
        "  userRatings[user].append(r)\n",
        "\n",
        "globalAverage = sum(b_allRatings) / len(b_allRatings)\n",
        "userAverage = {}\n",
        "for u in userRatings:\n",
        "  userAverage[u] = sum(userRatings[u]) / len(userRatings[u])\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "T2XA8sLO0xoR"
      },
      "id": "T2XA8sLO0xoR",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bias Model\n"
      ],
      "metadata": {
        "id": "XtPw-eNrCSiF"
      },
      "id": "XtPw-eNrCSiF"
    },
    {
      "cell_type": "code",
      "source": [
        "def MSE(predictions, labels):\n",
        "    differences = [(x-y)**2 for x,y in zip(predictions,labels)]\n",
        "    return sum(differences) / len(differences)\n",
        "\n",
        "alpha = globalAverage\n",
        "betaU = defaultdict(float)\n",
        "betaI = defaultdict(float)\n",
        "### DOING THIS\n",
        "ratingsTrain = allRatings\n",
        "#from hw3 \n",
        "# def iterate(lamb):\n",
        "#     newAlpha = 0\n",
        "#     for u,b,r in ratingsTrain:\n",
        "#         newAlpha += r - (betaU[u] + betaI[b])\n",
        "#     alpha = newAlpha / len(ratingsTrain)\n",
        "#     for u in ratingsPerUser:\n",
        "#         newBetaU = 0\n",
        "#         for b,r in ratingsPerUser[u]:\n",
        "#             newBetaU += r - (alpha + betaI[b])\n",
        "#         betaU[u] = newBetaU / (lamb + len(ratingsPerUser[u]))\n",
        "#     for b in ratingsPerItem:\n",
        "#         newBetaI = 0\n",
        "#         for u,r in ratingsPerItem[b]:\n",
        "#             newBetaI += r - (alpha + betaU[u])\n",
        "#         betaI[b] = newBetaI / (lamb + len(ratingsPerItem[b]))\n",
        "#     mse = 0\n",
        "#     for u,b,r in ratingsTrain:\n",
        "#         prediction = alpha + betaU[u] + betaI[b]\n",
        "#         mse += (r - prediction)**2\n",
        "#     regularizer = 0\n",
        "#     for u in betaU:\n",
        "#         regularizer += betaU[u]**2\n",
        "#     for b in betaI:\n",
        "#         regularizer += betaI[b]**2\n",
        "#     mse /= len(ratingsTrain)\n",
        "#     return mse, mse + lamb*regularizer\n",
        "\n",
        "class lf_model():\n",
        "  def __init__(self):\n",
        "    self.alpha = globalAverage\n",
        "    self.userBiases = defaultdict(float)\n",
        "    self.itemBiases = defaultdict(float)\n",
        "\n",
        "  def fit(self,lam):\n",
        "    itrs = 100\n",
        "    for i in range(itrs):\n",
        "      if i %10 == 0:\n",
        "        print(i)\n",
        "      for d in ratingsTrain:\n",
        "        u,i,r = d[0], d[1],d[2]\n",
        "        self.alpha += (r - (self.userBiases[u] + self.itemBiases[i]))\n",
        "      self.alpha /= len(ratingsTrain)\n",
        "      for u in ratingsPerUser:\n",
        "        items = [b for b, r in ratingsPerUser[u]]\n",
        "        ratings = [r for b, r in ratingsPerUser[u]]\n",
        "        self.userBiases[u] = sum([ratings[j] - (self.alpha + self.itemBiases[items[j]]) for j in range(len(items))])/(lam + len(set(items)))\n",
        "\n",
        "      for i in ratingsPerItem:\n",
        "        users = [u for u, r in ratingsPerItem[i]]\n",
        "        ratings = [r for u, r in ratingsPerItem[i]]\n",
        "        self.itemBiases[i] = sum([ratings[j] - (self.alpha + self.userBiases[users[j]]) for j in range(len(users))])/(lam + len(set(users)))\n",
        "    return self.alpha, self.userBiases, self.itemBiases\n",
        "  \n",
        "  def prediction(self,user, item):\n",
        "    return self.alpha + self.userBiases[user] + self.itemBiases[item]\n",
        "\n"
      ],
      "metadata": {
        "id": "Fj2yxKy0Idh9"
      },
      "id": "Fj2yxKy0Idh9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lm = 5\n",
        "mse,objective = iterate(lm)\n",
        "newMSE,newObjective = iterate(lm)\n",
        "iterations = 2\n",
        "while iterations < 10 or objective - newObjective > 0.0001:\n",
        "    mse, objective = newMSE, newObjective\n",
        "    newMSE, newObjective = iterate(lm)\n",
        "    iterations += 1\n",
        "    # print(\"Objective after \"\n",
        "    #     + str(iterations) + \" iterations = \" + str(newObjective))\n",
        "    if iterations%10 == 0:\n",
        "      print(\"MSE after \"\n",
        "        + str(iterations) + \" iterations = \" + str(newMSE))\n",
        "    \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GdhB4Q5d-aPr",
        "outputId": "ee649dc5-e6a7-4db9-e282-ffb0bc899445"
      },
      "id": "GdhB4Q5d-aPr",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE after 10 iterations = 1.1569389605313316\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reg = 5\n",
        "mod = lf_model()\n",
        "bestalpha, bestuserBiases, bestitemBiases = mod.fit(lam = reg)"
      ],
      "metadata": {
        "id": "JlYWFb6DWzF4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3709c15f-b50f-43e8-9897-7c98ae6fac09"
      },
      "id": "JlYWFb6DWzF4",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "10\n",
            "20\n",
            "30\n",
            "40\n",
            "50\n",
            "60\n",
            "70\n",
            "80\n",
            "90\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds = [np.clip(mod.prediction(u,i),0,5) for u,i,_ in ratingsValid]\n",
        "#preds = [np.clip((alpha+betaU[u] + betaI[i]),0,5) for u,i,_ in ratingsValid]\n",
        "labels = [r for _,_,r in ratingsValid]\n",
        "validMSE = MSE(preds, labels)#\n",
        "validMSE"
      ],
      "metadata": {
        "id": "j0PW3KdpJTcQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47695682-cbd7-4226-e026-852b1c704121"
      },
      "id": "j0PW3KdpJTcQ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.1134368375927364"
            ]
          },
          "metadata": {},
          "execution_count": 127
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Latent Factor Model"
      ],
      "metadata": {
        "id": "roZXfR81CXve"
      },
      "id": "roZXfR81CXve"
    },
    {
      "cell_type": "code",
      "source": [
        "userIDs = {}\n",
        "itemIDs = {}\n",
        "interactions = []\n",
        "for u,i,r in allRatings:\n",
        "    if not u in userIDs: userIDs[u] = len(userIDs)\n",
        "    if not i in itemIDs: itemIDs[i] = len(itemIDs)\n",
        "    interactions.append((u,i,r))"
      ],
      "metadata": {
        "id": "ua4VfKcDDOGB"
      },
      "id": "ua4VfKcDDOGB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = tf.keras.optimizers.Adam(0.01)\n",
        "class LatentFactorModel(tf.keras.Model):\n",
        "    def __init__(self, mu, K, lamb):\n",
        "        super(LatentFactorModel, self).__init__()\n",
        "        # Initialize to average\n",
        "        self.alpha = tf.Variable(mu)\n",
        "        # Initialize to small random values\n",
        "        self.betaU = tf.Variable(tf.random.normal([len(userIDs)],stddev=0.001))\n",
        "        self.betaI = tf.Variable(tf.random.normal([len(itemIDs)],stddev=0.001))\n",
        "        self.gammaU = tf.Variable(tf.random.normal([len(userIDs),K],stddev=0.001))\n",
        "        self.gammaI = tf.Variable(tf.random.normal([len(itemIDs),K],stddev=0.001))\n",
        "        self.lamb = lamb\n",
        "\n",
        "    # Prediction for a single instance (useful for evaluation)\n",
        "    def predict(self, u, i):\n",
        "        p = self.alpha + self.betaU[u] + self.betaI[i] +\\\n",
        "            tf.tensordot(self.gammaU[u], self.gammaI[i], 1)\n",
        "        return p\n",
        "\n",
        "    # Regularizer\n",
        "    def reg(self):\n",
        "        return self.lamb * (tf.reduce_sum(self.betaU**2) +\\\n",
        "                            tf.reduce_sum(self.betaI**2) +\\\n",
        "                            tf.reduce_sum(self.gammaU**2) +\\\n",
        "                            tf.reduce_sum(self.gammaI**2))\n",
        "    \n",
        "    # Prediction for a sample of instances\n",
        "    def predictSample(self, sampleU, sampleI):\n",
        "        u = tf.convert_to_tensor(sampleU, dtype=tf.int32)\n",
        "        i = tf.convert_to_tensor(sampleI, dtype=tf.int32)\n",
        "        beta_u = tf.nn.embedding_lookup(self.betaU, u)\n",
        "        beta_i = tf.nn.embedding_lookup(self.betaI, i)\n",
        "        gamma_u = tf.nn.embedding_lookup(self.gammaU, u)\n",
        "        gamma_i = tf.nn.embedding_lookup(self.gammaI, i)\n",
        "        pred = self.alpha + beta_u + beta_i +\\\n",
        "               tf.reduce_sum(tf.multiply(gamma_u, gamma_i), 1)\n",
        "        return pred\n",
        "    \n",
        "    # Loss\n",
        "    def call(self, sampleU, sampleI, sampleR):\n",
        "        pred = self.predictSample(sampleU, sampleI)\n",
        "        r = tf.convert_to_tensor(sampleR, dtype=tf.float32)\n",
        "        return tf.nn.l2_loss(pred - r) / len(sampleR)"
      ],
      "metadata": {
        "id": "hSDkKBs7CW1j"
      },
      "id": "hSDkKBs7CW1j",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modelLFM = LatentFactorModel(globalAverage, 2,0.00001)"
      ],
      "metadata": {
        "id": "JKChenY_DqrY"
      },
      "id": "JKChenY_DqrY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def trainingStep(model, interactions):\n",
        "    Nsamples = 30000\n",
        "    with tf.GradientTape() as tape:\n",
        "        sampleU, sampleI, sampleR = [], [], []\n",
        "        for _ in range(Nsamples):\n",
        "            u,i,r = random.choice(interactions)\n",
        "            sampleU.append(userIDs[u])\n",
        "            sampleI.append(itemIDs[i])\n",
        "            sampleR.append(r)\n",
        "\n",
        "        loss = model(sampleU,sampleI,sampleR)\n",
        "        loss += model.reg()\n",
        "    gradients = tape.gradient(loss, model.trainable_variables)\n",
        "    optimizer.apply_gradients((grad, var) for\n",
        "                              (grad, var) in zip(gradients, model.trainable_variables)\n",
        "                              if grad is not None)\n",
        "    return loss.numpy()"
      ],
      "metadata": {
        "id": "NkYYlo_CDxkj"
      },
      "id": "NkYYlo_CDxkj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(100):\n",
        "    obj = trainingStep(modelLFM, interactions[:190000])\n",
        "    if (i % 10 == 9): print(\"iteration \" + str(i+1) + \", objective = \" + str(obj))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-i5btYseHgYn",
        "outputId": "3bc2745f-9c7f-4d55-ae3a-62f2e7a00273"
      },
      "id": "-i5btYseHgYn",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iteration 10, objective = 0.820074\n",
            "iteration 20, objective = 0.74256504\n",
            "iteration 30, objective = 0.6948073\n",
            "iteration 40, objective = 0.6760961\n",
            "iteration 50, objective = 0.6409778\n",
            "iteration 60, objective = 0.6210869\n",
            "iteration 70, objective = 0.57874256\n",
            "iteration 80, objective = 0.56941396\n",
            "iteration 90, objective = 0.5695267\n",
            "iteration 100, objective = 0.5642639\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds = [np.clip((modelLFM.predict(userIDs[u], itemIDs[b]).numpy()),0,5) for u,b,_ in ratingsValid]\n",
        "labels = [r for _,_,r in ratingsValid]\n",
        "validMSE = MSE(preds, labels)\n",
        "validMSE"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rcNK-7xzIygt",
        "outputId": "427e9c91-5e70-4ff4-c882-fa32e295e522"
      },
      "id": "rcNK-7xzIygt",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.5112906806164588"
            ]
          },
          "metadata": {},
          "execution_count": 132
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Surprise"
      ],
      "metadata": {
        "id": "CSfQRCOULwQm"
      },
      "id": "CSfQRCOULwQm"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install surprise\n",
        "from surprise import SVD, Reader, Dataset\n",
        "from surprise.model_selection import train_test_split\n",
        "from surprise.model_selection import GridSearchCV"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VdDaHKR8LyRI",
        "outputId": "94d8f7c3-4d0e-4f88-cf31-49da602b7403"
      },
      "id": "VdDaHKR8LyRI",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting surprise\n",
            "  Downloading surprise-0.1-py2.py3-none-any.whl (1.8 kB)\n",
            "Collecting scikit-surprise\n",
            "  Downloading scikit-surprise-1.1.1.tar.gz (11.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 11.8 MB 7.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-surprise->surprise) (1.2.0)\n",
            "Requirement already satisfied: numpy>=1.11.2 in /usr/local/lib/python3.7/dist-packages (from scikit-surprise->surprise) (1.21.6)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-surprise->surprise) (1.7.3)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from scikit-surprise->surprise) (1.15.0)\n",
            "Building wheels for collected packages: scikit-surprise\n",
            "  Building wheel for scikit-surprise (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for scikit-surprise: filename=scikit_surprise-1.1.1-cp37-cp37m-linux_x86_64.whl size=1633967 sha256=f76c38c44e027bbcb8814854e1adc14b2480407a107b06298001e94346003c0d\n",
            "  Stored in directory: /root/.cache/pip/wheels/76/44/74/b498c42be47b2406bd27994e16c5188e337c657025ab400c1c\n",
            "Successfully built scikit-surprise\n",
            "Installing collected packages: scikit-surprise, surprise\n",
            "Successfully installed scikit-surprise-1.1.1 surprise-0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reader = Reader(line_format='user item rating', sep=',', skip_lines = 1)\n",
        "data = Dataset.load_from_file(\"train_Interactions.csv\", reader=reader)\n",
        "# param_grid = {'n_epochs': [47], 'lr_all': [0.0045, 0.00475, 0.005],\n",
        "#               'reg_all': [0.5, 0.3, 0.4]}\n",
        "# grid_search = GridSearchCV(SVD, param_grid, measures=['rmse'], cv = 3)   \n",
        "# grid_search.fit(data)\n",
        "# print(grid_search.best_params['rmse'])         \n"
      ],
      "metadata": {
        "id": "NyOumhgDL8ql"
      },
      "id": "NyOumhgDL8ql",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainset = data.build_full_trainset()"
      ],
      "metadata": {
        "id": "HF8eG-qMLvSM"
      },
      "id": "HF8eG-qMLvSM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = SVD(n_epochs = 50, lr_all = 0.0047, reg_all = 0.32)\n",
        "\n",
        "model.fit(trainset)\n",
        "# predictions = model.test(testset)\n",
        "# sse = 0\n",
        "# for p in predictions:\n",
        "#     sse += (p.r_ui - p.est)**2\n",
        "\n",
        "# print(sse / len(predictions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EZ2_IIH7ZWy1",
        "outputId": "35c59c67-6cd4-4eda-edaa-153f938b0df0"
      },
      "id": "EZ2_IIH7ZWy1",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<surprise.prediction_algorithms.matrix_factorization.SVD at 0x7f3cfd993e50>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Rating Answers"
      ],
      "metadata": {
        "id": "_edTtrJH_vru"
      },
      "id": "_edTtrJH_vru"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b9bd53b3",
      "metadata": {
        "id": "b9bd53b3"
      },
      "outputs": [],
      "source": [
        "suprise_pred = model.test(pairs_Ratings)\n",
        "predictions = open(\"predictions_Rating.csv\", 'w')\n",
        "i = 0\n",
        "for l in open(\"pairs_Rating.csv\"):\n",
        "    if l.startswith(\"userID\"):\n",
        "      predictions.write(l)\n",
        "      continue\n",
        "    u,b = l.strip().split(',') # Read the user and item from the \"pairs\" file and write out your prediction\n",
        "    #predictions.write(u + ',' + b + ',' + str(np.clip(mod.prediction(u,b),0,5)) + '\\n')\n",
        "    #predictions.write(u + ',' + b + ',' + str(np.clip((alpha+betaU[u] + betaI[b]),0,5)) + '\\n')\n",
        "    predictions.write(u + ',' + b + ',' + str(np.clip(suprise_pred[i].est,0,5)) + '\\n')\n",
        "    i+=1\n",
        "    # try:\n",
        "    #   pred = np.clip((modelLFM.predict(userIDs[u], itemIDs[b]).numpy()),0,5)\n",
        "    # except:\n",
        "    #   if u in userRatings:\n",
        "    #     pred =  userAverage[u]\n",
        "    #   else:\n",
        "    #     pred = globalAverage\n",
        "    #predictions.write(u + ',' + b + ',' + str(pred) + '\\n')\n",
        "  \n",
        "predictions.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Read Prediction"
      ],
      "metadata": {
        "id": "5BaXrnfjrG5v"
      },
      "id": "5BaXrnfjrG5v"
    },
    {
      "cell_type": "code",
      "source": [
        "#add 1 to every book which is read\n",
        "ratingsValid = allRatings[190000:]\n",
        "ratingsValid = [i + (1,) for i in ratingsValid]\n",
        "ratingsValid[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W6EdpcbUmzdo",
        "outputId": "c475daaa-7750-468c-af22-86f8f7181ed1"
      },
      "id": "W6EdpcbUmzdo",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('u59070515', 'b55084829', 5, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7c9eea8f",
      "metadata": {
        "id": "7c9eea8f"
      },
      "outputs": [],
      "source": [
        "booksperUser = defaultdict(list)\n",
        "userperBook = defaultdict(list)\n",
        "for u,b,_ in allRatings:\n",
        "    booksperUser[u].append(b)\n",
        "    userperBook[b].append(u)\n",
        "\n",
        "all_books = set(userperBook.keys())\n",
        "booksperUserReadVal = defaultdict(list)\n",
        "for u,b,_,_ in ratingsValid:\n",
        "    booksperUserReadVal[u].append(b)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Adding random negative samples to the validation set\n",
        "val_pairs = set()\n",
        "for user in booksperUserReadVal.keys():\n",
        "  no_books_read = len(booksperUserReadVal[user])\n",
        "  books_not_read = list(all_books.difference(set(booksperUser[user])))\n",
        "  for _ in range(no_books_read):\n",
        "    book = random.choice(books_not_read)\n",
        "    if (user,book, 'NA', 0) not in val_pairs:\n",
        "      book = book\n",
        "    else:\n",
        "      while (user,book, 'NA', 0) in val_pairs:\n",
        "        book = random.choice(books_not_read)\n",
        "    val_pairs.add((user,book,'NA',0))\n",
        "    ratingsValid.append((user,book,'NA',0)) \n",
        "\n",
        "len(ratingsValid)"
      ],
      "metadata": {
        "id": "JEU2I2an6eRI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6eee1eaf-dc52-4b7e-e4c9-273f94f18efb"
      },
      "id": "JEU2I2an6eRI",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20000"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "abb17ed7",
      "metadata": {
        "id": "abb17ed7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3d68ce0-678a-4760-dc3e-01ffb60be40e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "190000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "28.426092160383003"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "# Copied from baseline code\n",
        "bookCountAll = defaultdict(int)\n",
        "bookCountTrain = defaultdict(int)\n",
        "totalReadAll,totalReadTrain = 0,0\n",
        "\n",
        "for user,book,_ in ratingsTrain:#readCSV(\"train_Interactions.csv.gz\"):\n",
        "    bookCountTrain[book] += 1\n",
        "    totalReadTrain += 1\n",
        "for user,book,_ in ratingsTrain:#readCSV(\"train_Interactions.csv.gz\"):\n",
        "    bookCountAll[book] += 1\n",
        "    totalReadAll += 1\n",
        "\n",
        "#mostPopular = [(bookCountTrain[x], x) for x in bookCountTrain]\n",
        "mostPopular = [(bookCountAll[x], x) for x in bookCountAll]\n",
        "mostPopular.sort()\n",
        "mostPopular.reverse()\n",
        "print(totalReadTrain)\n",
        "\n",
        "avgBookCount = np.mean(list(bookCountAll.values()))\n",
        "avgBookCount\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "87e03b83",
      "metadata": {
        "id": "87e03b83"
      },
      "outputs": [],
      "source": [
        "# Changing threshold\n",
        "return2 = set()\n",
        "count = 0\n",
        "threshold = 0.75\n",
        "for bookCount, book in mostPopular:\n",
        "    count += bookCount\n",
        "    return2.add(book)\n",
        "    if count > totalReadAll*threshold: break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "04a6f2e1",
      "metadata": {
        "id": "04a6f2e1"
      },
      "outputs": [],
      "source": [
        "def Jaccard(s1, s2):\n",
        "  if not isinstance(s1,set):\n",
        "    s1 = set(s1)\n",
        "  if not isinstance(s2,set):\n",
        "    s2 = set(s2)\n",
        "  numer = len(s1.intersection(s2))\n",
        "  denom = len(s1.union(s2))\n",
        "  if denom == 0:\n",
        "      return 0\n",
        "  return numer / denom\n",
        "\n",
        "def CosineSet(s1, s2):\n",
        "    # Not a proper implementation, operates on sets so correct for interactions only\n",
        "    if not isinstance(s1,set):\n",
        "      s1 = set(s1)\n",
        "    if not isinstance(s2,set):\n",
        "      s2 = set(s2)\n",
        "    numer = len(s1.intersection(s2))\n",
        "    denom = math.sqrt(len(s1)) * math.sqrt(len(s2))\n",
        "    if denom == 0:\n",
        "        return 0\n",
        "    return numer / denom\n",
        "\n",
        "booksperUserTrain = defaultdict(list)\n",
        "userperBookTrain = defaultdict(list)\n",
        "for u,b,_ in ratingsTrain:\n",
        "    booksperUserTrain[u].append(b)\n",
        "    userperBookTrain[b].append(u)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# def predictRating_41(user, book):\n",
        "#   Csimilarities = []\n",
        "#   Jsimilarities = []\n",
        "#   for d in booksperUser[user]:\n",
        "#     #d is book user has read in training\n",
        "#     if d == book: continue\n",
        "#     Jsimilarities.append(Jaccard(userperBook[book],userperBook[d]))\n",
        "#     Csimilarities.append(CosineSet(userperBookTrain[book],userperBookTrain[d]))\n",
        "#   if ((Csimilarities and max(Csimilarities) > 0.013) and (Jsimilarities and max(Jsimilarities) > 0.013) or \\\n",
        "#       len(userperBook[book])>40) and  book in return2:\n",
        "#     return 1\n",
        "#   return 0\n",
        "\n",
        "def predictRating_41(user, book):\n",
        "  Csimilarities = []\n",
        "  Jsimilarities = []\n",
        "  for d in booksperUser[user]:\n",
        "    #d is book user has read in training\n",
        "    if d == book: continue\n",
        "    Jsimilarities.append(Jaccard(userperBook[book],userperBook[d]))\n",
        "    Csimilarities.append(CosineSet(userperBook[book],userperBook[d]))\n",
        "  mx = 0\n",
        "  if Jsimilarities:\n",
        "      mx = max(Jsimilarities)\n",
        "  elif len(Jsimilarities) == 0:\n",
        "    mx = 0\n",
        "  if book in return2 or len(userperBook[book])>40:\n",
        "    return 1 + mx\n",
        "  return mx\n",
        "\n",
        "# def predictRating_42(user, book):\n",
        "#   Csimilarities = []\n",
        "#   Jsimilarities = []\n",
        "#   for d in userperBook[book]:\n",
        "#     #d is user\n",
        "#     if d == user: continue\n",
        "#     Jsimilarities.append(Jaccard(booksperUserTrain[user],booksperUserTrain[d]))\n",
        "#     Csimilarities.append(CosineSet(booksperUser[user],booksperUser[d]))\n",
        "#   if ((Csimilarities and max(Csimilarities)) > 0.013 or \\\n",
        "#       len(userperBook[book]>40) or (Jsimilarities and max(Jsimilarities) >0.013)) and book in return2:\n",
        "#     return 1\n",
        "#   return 0\n",
        "\n",
        "# preds = [predictRating_41(u,b) for u,b,_,_ in ratingsValid]\n",
        "# correct = sum([ratingsValid[i][3]  == preds[i] for i in range(len(ratingsValid))])\n",
        "# y = [x for _,_,_,x in ratingsValid]\n",
        "# acc4 = correct/len(preds)\n",
        "# acc4 #0.75955 #0.7619 "
      ],
      "metadata": {
        "id": "NCXYvGIMz8ol"
      },
      "id": "NCXYvGIMz8ol",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TP = sum([(p and l) for (p,l) in zip(preds, y)])\n",
        "# FP = sum([(p and not l) for (p,l) in zip(preds, y)])\n",
        "# TN = sum([(not p and not l) for (p,l) in zip(preds, y)])\n",
        "# FN = sum([(not p and l) for (p,l) in zip(preds, y)])\n",
        "# TP,FP, TN,FN"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8StxCsDZjfW7",
        "outputId": "1242c314-13d5-4f73-b11a-7ff2a86d065b"
      },
      "id": "8StxCsDZjfW7",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7028, 1762, 8238, 2972)"
            ]
          },
          "metadata": {},
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pairs_read_users = defaultdict(list)\n",
        "for u,b in pairs_Read:\n",
        "  pairs_read_users[u].append((predictRating_41(u,b),b))\n",
        "\n",
        "final_scores = {}\n",
        "for u in pairs_read_users:\n",
        "  scores = sorted(pairs_read_users[u], reverse = True)\n",
        "  for i in range(len(scores)):\n",
        "    pred = 0\n",
        "    b = scores[i][1]\n",
        "    if i < len(scores)//2: #you are in first half\n",
        "         pred = 1\n",
        "    final_scores[(u,b)] =  pred\n",
        "  "
      ],
      "metadata": {
        "id": "hhEXgxG3nZGs"
      },
      "id": "hhEXgxG3nZGs",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3e68cbed",
      "metadata": {
        "id": "3e68cbed"
      },
      "outputs": [],
      "source": [
        "predictions = open(\"predictions_Read.csv\", 'w')\n",
        "dct = {}\n",
        "for l in open(\"pairs_Read.csv\"):\n",
        "    if l.startswith(\"userID\"):\n",
        "        predictions.write(l)\n",
        "        continue\n",
        "    u,b = l.strip().split(',')\n",
        "    \n",
        "    preds = final_scores[(u,b)]\n",
        "    predictions.write(u + ',' + b + \",\"+str(preds)+\"\\n\")\n",
        "\n",
        "predictions.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3000bdde",
      "metadata": {
        "id": "3000bdde"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}